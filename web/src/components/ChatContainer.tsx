"use client";

/**
 * Chat container component with CopilotKit integration.
 * AI instructions are handled server-side in agent.py - this is a pure UI layer.
 *
 * State sharing is set up between Python backend and frontend via LangGraph protocol.
 * Progress indicators are rendered via useCoAgentStateRender hook, which receives
 * real-time updates from copilotkit_emit_state() calls in the Python agent.
 *
 * Citations are rendered via custom markdownTagRenderers that handle <cite> tags
 * generated by the backend's citation processor. Each assistant message displays
 * its own sources accordion below the message content.
 */

import { useState, useCallback } from "react";
import { CopilotChat } from "@copilotkit/react-ui";
import { useChatContext } from "@copilotkit/react-ui";
import type { AssistantMessageProps } from "@copilotkit/react-ui";
import { useCoAgent, useCoAgentStateRender } from "@copilotkit/react-core";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import rehypeRaw from "rehype-raw";
import "@copilotkit/react-ui/styles.css";
import { RAGState, initialRAGState } from "@/types/rag";
import {
  sourceTagRenderers,
  CitationProvider,
  MessageCitationProvider,
  SourcesAccordion,
  SourceViewDialog,
  useCitationContext,
} from "./Sources";

function SearchProgress({ message }: { message: string }) {
  return (
    <div className="flex items-center gap-2 px-4 py-3 bg-blue-50 border border-blue-200 rounded-lg mx-4 my-2">
      <div className="animate-spin h-4 w-4 border-2 border-blue-500 border-t-transparent rounded-full" />
      <span className="text-sm text-blue-700">{message}</span>
    </div>
  );
}

/**
 * Custom assistant message component that renders sources below each response.
 * Each message gets its own MessageCitationProvider to isolate citations per response.
 *
 * Note: CopilotKit handles the avatar/wrapper - we only provide the message content.
 */
function CustomAssistantMessage(props: AssistantMessageProps) {
  const { icons } = useChatContext();
  const { message, isLoading } = props;
  const { onViewCitation } = useCitationContext();

  // generativeUI contains output from useCoAgentStateRender (e.g., SearchProgress)
  // It can be a function or a ReactNode
  const generativeUI = message?.generativeUI;
  const renderedGenerativeUI = typeof generativeUI === "function" ? generativeUI() : generativeUI;

  return (
    <MessageCitationProvider onViewCitation={onViewCitation}>
      <div>
        {/* Render generative UI (e.g., search progress from useCoAgentStateRender) */}
        {renderedGenerativeUI && <div className="mb-2">{renderedGenerativeUI}</div>}

        <div className="prose prose-sm max-w-none prose-p:my-2 prose-headings:my-3">
          <ReactMarkdown
            remarkPlugins={[remarkGfm]}
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            rehypePlugins={[rehypeRaw as any]}
            components={sourceTagRenderers}
          >
            {message?.content || ""}
          </ReactMarkdown>
        </div>
        {isLoading && (
          <div className="mt-2">
            {icons.spinnerIcon}
          </div>
        )}
        {!isLoading && (
          <div className="mt-3 mb-4">
            <SourcesAccordion />
          </div>
        )}
      </div>
    </MessageCitationProvider>
  );
}

interface ChatContainerProps {
  /** Callback when user sends a message (for title generation and timestamp updates) */
  onMessageSent?: (content: string) => void;
  /** Whether the chat is read-only (e.g., archived conversations) */
  disabled?: boolean;
}

export function ChatContainer({ onMessageSent, disabled }: ChatContainerProps) {
  const { state } = useCoAgent<RAGState>({
    name: "default",
    initialState: initialRAGState,
  });

  // Citation dialog state
  const [selectedChunkId, setSelectedChunkId] = useState<string | null>(null);
  const [dialogOpen, setDialogOpen] = useState(false);

  const handleViewCitation = useCallback((chunkId: string) => {
    setSelectedChunkId(chunkId);
    setDialogOpen(true);
  }, []);

  const handleSubmitMessage = useCallback(
    (message: string) => {
      onMessageSent?.(message);
    },
    [onMessageSent]
  );

  // Render search progress during agent execution
  useCoAgentStateRender<RAGState>({
    name: "default",
    render: ({ state }) => {
      if (state.search_progress) {
        return <SearchProgress message={state.search_progress} />;
      }
      return null;
    },
  });

  return (
    <CitationProvider onViewCitation={handleViewCitation}>
      <div className="flex-1 flex flex-col h-[calc(100vh-8rem)]">
        {state.error_message && (
          <div className="px-4 py-2 bg-red-50 border-b border-red-200">
            <div className="text-sm text-red-700">
              Error: {state.error_message}
            </div>
          </div>
        )}
        <CopilotChat
          labels={{
            title: "MTSS Assistant",
            initial: "Hello! I can help you find solutions to technical issues on your vessel. Ask me about past maintenance problems, equipment failures, or search our knowledge base for technical documentation and procedures.",
            placeholder: disabled
              ? "This conversation is archived (read-only)"
              : "Describe an issue or search for technical information...",
          }}
          className={`flex-1 [&_.copilotKitChat]:h-full [&_.copilotKitMessages]:max-h-[calc(100vh-16rem)] ${
            disabled ? "[&_.copilotKitInput]:opacity-50 [&_.copilotKitInput]:pointer-events-none" : ""
          }`}
          markdownTagRenderers={sourceTagRenderers}
          AssistantMessage={CustomAssistantMessage}
          onSubmitMessage={disabled ? undefined : handleSubmitMessage}
        />

        {/* Dialog for viewing full source content */}
        <SourceViewDialog
          chunkId={selectedChunkId}
          open={dialogOpen}
          onOpenChange={setDialogOpen}
        />
      </div>
    </CitationProvider>
  );
}
